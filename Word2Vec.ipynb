{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***this code reads a file , tokenize it , and remove the stop words from the file , then save it to other file***"
      ],
      "metadata": {
        "id": "3ZZJU0OlKhui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/res/ArabicCorpus.txt\", \"r\")\n",
        "read = (f.readlines())\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "cachedStopWords = stopwords.words(\"arabic\")\n",
        "\n",
        "def tokenizer(text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords])\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/res/NoStopWordsArabicCorpus.txt\", \"w\")\n",
        "for row in read:\n",
        "  var = tokenizer(row)\n",
        "  f.write(var)\n",
        "  f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "F9aEIvwbGrOw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The corpus is a file on my Google Drive , Named \"NoStopWordsArabicCorpus.txt\"\n",
        "which is a corpus filtered from arabic corpus contains over 250k arabic words , this corpus contains no stopwords,This code prints the Top 10 similars words for a cerain word , and the COS-SIM between two words**"
      ],
      "metadata": {
        "id": "AS6Yga5IAaBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To open a file from my google drive and read it:\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/res/NoStopWordsArabicCorpus.txt\", \"r\")\n",
        "read = (f.readlines())\n",
        "\n",
        "#in this section , im spliting the data via space , and \n",
        "#saving the values into array -data set- to pass it to the model\n",
        "data = []\n",
        "for row in read:\n",
        "  data.append(row.split())"
      ],
      "metadata": {
        "id": "eBc1rwIEKWbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buildeng the model from the read data"
      ],
      "metadata": {
        "id": "NizIjIhsKaDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6f2td0oAZGR"
      },
      "outputs": [],
      "source": [
        "\n",
        "#import the library\n",
        "import gensim \n",
        "\n",
        "#Defining the model\n",
        "model = gensim.models.Word2Vec(\n",
        "        data,\n",
        "        size=100,\n",
        "        window=10,\n",
        "        min_count=1,\n",
        "        workers=10,\n",
        "        iter=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Top 10 similars word***"
      ],
      "metadata": {
        "id": "eBQ22x-cKDNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sims = model.wv.most_similar('فضاء', topn=10)\n",
        "print(sims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3zasXVHJ3OR",
        "outputId": "e2615dbb-524b-4043-c10b-072c9e803ffb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('الفيزياء', 0.9948766231536865), ('مرصد', 0.9931848049163818), ('الهيدروكربونات', 0.993013858795166), ('لمتوسط', 0.9911755919456482), ('التداخل', 0.9909759759902954), ('تحريك', 0.9907614588737488), ('تاربوك', 0.9907497763633728), ('للمسح', 0.9900791049003601), ('لباطن', 0.990059494972229), ('وتأثيرها', 0.9899010062217712)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cosine Similarity Between two words***"
      ],
      "metadata": {
        "id": "aLRCzUHsKIBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos = model.wv.similarity('فضاء', 'سماء')\n",
        "print(cos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxwLNQ0gKB2o",
        "outputId": "6940d564-f6f7-40bb-d74b-16f5aefa4ec3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9322804\n"
          ]
        }
      ]
    }
  ]
}