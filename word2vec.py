# -*- coding: utf-8 -*-
"""Word2Vec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19QzZ7jhji-KFOXjin14ks7bE_OCr72bD

***this code reads a file , tokenize it , and remove the stop words from the file , then save it to other file***
"""

f = open("/content/drive/MyDrive/Colab Notebooks/res/ArabicCorpus.txt", "r")
read = (f.readlines())

from nltk.corpus import stopwords

cachedStopWords = stopwords.words("arabic")

def tokenizer(text):
        return ' '.join([word for word in text.split() if word not in cachedStopWords])
f = open("/content/drive/MyDrive/Colab Notebooks/res/NoStopWordsArabicCorpus.txt", "w")
for row in read:
  var = tokenizer(row)
  f.write(var)
  f.write("\n")

"""**The corpus is a file on my Google Drive , Named "NoStopWordsArabicCorpus.txt"
which is a corpus filtered from arabic corpus contains over 250k arabic words , this corpus contains no stopwords,This code prints the Top 10 similars words for a cerain word , and the COS-SIM between two words**
"""

# To open a file from my google drive and read it:
f = open("/content/drive/MyDrive/Colab Notebooks/res/NoStopWordsArabicCorpus.txt", "r")
read = (f.readlines())

#in this section , im spliting the data via space , and 
#saving the values into array -data set- to pass it to the model
data = []
for row in read:
  data.append(row.split())

"""Buildeng the model from the read data"""

#import the library
import gensim 

#Defining the model
model = gensim.models.Word2Vec(
        data,
        size=100,
        window=10,
        min_count=1,
        workers=10,
        iter=12)

""" ***Top 10 similars word***"""

sims = model.wv.most_similar('فضاء', topn=10)
print(sims)

"""***Cosine Similarity Between two words***"""

cos = model.wv.similarity('فضاء', 'سماء')
print(cos)